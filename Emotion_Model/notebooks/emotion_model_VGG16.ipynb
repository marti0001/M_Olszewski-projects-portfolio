{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79a13c-1d0a-4c76-aa9b-853d5e56475f",
   "metadata": {},
   "source": [
    "# Model VGG16\n",
    "\n",
    "- Prosty model wyrózniajacy sie prostą i elegancką archtekturą zbudowaną z kolejnych warstw konwolucyjnych\n",
    "- Model zawiera 16 warstw uczących sie wag (13 konwolucyjnych + 3 w pełni połączone warstwy\n",
    "- Wszystkie wartwy konwolucyjne używają filtrów o wymiarach 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9cbecd-9ce4-40ec-be79-c4b8ee3d3d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from keras.callbacks import Callback, EarlyStopping ,ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
    "from keras.preprocessing import image\n",
    "from livelossplot import PlotLossesKeras \n",
    "import cv2\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ecda60-516c-4963-9595-378b776e6bab",
   "metadata": {},
   "source": [
    "### Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f151a83-53e3-47b3-bcb9-d1e249fcb53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"..\\input\\train\"\n",
    "test_dir = r\"..\\input\\test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c298e090-67e0-4e94-8f22-5b92e4136df1",
   "metadata": {},
   "source": [
    "### Tworzenie generatora danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9b7705-3bbd-422c-a634-5defcd99c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1.0/255.0, validation_split = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(f\"Number of classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cdbf0a2-8ade-439c-a5a4-997eb2ff8aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class indices: {'angry': 0, 'disgusted': 1, 'fearful': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprised': 6}\n",
      "Validation class indices: {'angry': 0, 'disgusted': 1, 'fearful': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprised': 6}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train class indices: {train_generator.class_indices}\")\n",
    "print(f\"Validation class indices: {validation_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9589c7-1408-4829-92ca-1567f92397d0",
   "metadata": {},
   "source": [
    "### Ładowanie modelu i konfiguracja modelu bazowego\n",
    " usuwamy warstwy klsyfikacyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6adfd07-7f5b-42f9-9ed5-ccd8295bc7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False,input_shape = (128,128,3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46dd7b65-7d99-44b1-874e-d1cc4ea6f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer 0 : input_layer, Trainable: False\n",
      " Layer 1 : block1_conv1, Trainable: False\n",
      " Layer 2 : block1_conv2, Trainable: False\n",
      " Layer 3 : block1_pool, Trainable: False\n",
      " Layer 4 : block2_conv1, Trainable: True\n",
      " Layer 5 : block2_conv2, Trainable: True\n",
      " Layer 6 : block2_pool, Trainable: True\n",
      " Layer 7 : block3_conv1, Trainable: True\n",
      " Layer 8 : block3_conv2, Trainable: True\n",
      " Layer 9 : block3_conv3, Trainable: True\n",
      " Layer 10 : block3_pool, Trainable: True\n",
      " Layer 11 : block4_conv1, Trainable: True\n",
      " Layer 12 : block4_conv2, Trainable: True\n",
      " Layer 13 : block4_conv3, Trainable: True\n",
      " Layer 14 : block4_pool, Trainable: True\n",
      " Layer 15 : block5_conv1, Trainable: True\n",
      " Layer 16 : block5_conv2, Trainable: True\n",
      " Layer 17 : block5_conv3, Trainable: True\n",
      " Layer 18 : block5_pool, Trainable: True\n"
     ]
    }
   ],
   "source": [
    "#Zamrozenie wszystkich warstw\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "i = 15\n",
    "\n",
    "# Odmrazanie ostatnich i warstw\n",
    "for layer in base_model.layers[-i:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "#Sprawdzenie statusu warstw\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(f' Layer {i} : {layer.name}, Trainable: {layer.trainable}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838087c8-2998-4c7d-9147-475fa52e9ad7",
   "metadata": {},
   "source": [
    "## Budowa modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c226985b-02b3-461e-a91d-12c3bc013ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849546df-af74-4c5e-97e3-f29fe5ca34c9",
   "metadata": {},
   "source": [
    "### Konfiguracja szkolenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11ed62c2-9d9a-4f27-91a0-e9ef5d423bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    PlotLossesKeras(),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1),\n",
    "    \n",
    "    ModelCheckpoint(filepath= r'..\\models\\emotion_model_VGG16_model_{epoch:02d}_{val_loss:.2f}.keras', \n",
    "                    monitor='val_loss', save_best_only=True, mode='min' , verbose=1),\n",
    "    ReduceLROnPlateau( monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='auto', min_lr=1e-6 ) \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7680cf-1f3e-4747-874a-65ca7ef50f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programy\\Anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 88/718\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00:09\u001b[0m 11s/step - accuracy: 0.2098 - loss: 4.5616"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=validation_generator\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40a912-a7a2-4e5f-93ac-bb8afa170a20",
   "metadata": {},
   "source": [
    "## Ocena modelu na danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f94fd1-c2e9-4032-9e8c-ba277c793e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b3a52-4cd9-4239-8f03-ca560af089e8",
   "metadata": {},
   "source": [
    "## Wnioski\n",
    "\n",
    "Po zwiekszeniu obrazu z 64x64x3 na 128x128x3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
